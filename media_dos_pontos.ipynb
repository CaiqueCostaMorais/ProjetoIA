{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b>IMPORTAÇÃO DE BIBLIOTECAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import dlib\n",
    "import pandas\n",
    "import math\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b>CÁLCULO DOS LANDMARKS FACIAIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPoints(path_land_pred, path_png, option):\n",
    "    #1º PASSO (PRÉ-PROCESSAMENTO): CARREGAMOS A IMAGEM, APLICAMOS A ESCALA DE CINZA E DEFINIMOS O DETECTOR FACIAL E O DE LANDMARKS \n",
    "    img = cv2.imread(path_png)\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    mask = np.zeros_like(img_gray)\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor = dlib.shape_predictor(path_land_pred)\n",
    "    faces = detector(img_gray)\n",
    "    #2º PASSO (PROCESSAMENTO): APLICAMOS O DETECTOR DE LANDMARKS, E DEFINIMOS OS PONTOS X E Y DOS 81 PONTOS FACIAIS\n",
    "    for face in faces:\n",
    "        landmarks = predictor(img_gray, face)\n",
    "        landmarks_points = []\n",
    "        val_x = []\n",
    "        val_y = []\n",
    "        for n in range(0, 81):\n",
    "            x = landmarks.part(n).x\n",
    "            y = landmarks.part(n).y\n",
    "            landmarks_points.append((x, y))\n",
    "            cv2.circle(img, (x, y), 3, (0, 0, 255), -1)\n",
    "            points = np.array(landmarks_points, np.int32)\n",
    "    #3º PASSO (SAÍDA): RETORNAMOS EM 1 A IMAGEM COM OS LANDMARKS, EM 2 A IMAGEM INICIAL, OU O ARRAY DOS LANDMARKS\n",
    "    if option == '1':\n",
    "        cv2.imshow(\"Image 1\", img)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "        cv2.imwrite('../Imagens/Ontario/result/test_woman2.jpg', img)\n",
    "        \n",
    "    elif option == '2':\n",
    "        img_new = cv2.imread(path_png)\n",
    "        cv2.imshow(\"Image 2\", img_new)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "    else:\n",
    "        return landmarks_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b>CRIAÇÃO DAS MÁSCARAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1º PASSO (MÉDIA DOS PONTOS): CALCULAMOS A MÉDIAS DOS LANDMARKS DAS FACES QUE FORAM CARREGADAS\n",
    "def calculo(ldmk_points):\n",
    "    mean_matrix = []\n",
    "    mean_matrix = np.matrix.round(sum(np.array(ldmk_points))/len(ldmk_points))\n",
    "    mean_matrix = mean_matrix.astype('int')\n",
    "                \n",
    "    return mean_matrix\n",
    "\n",
    "#2º PASSO (MÁSCARA - PONTOS): APLICAMOS A MÉDIA DOS PONTOS EM UMA IMAGEM EM BRANCO, ASSIM CRIANDO UMA MÁSCARA DA MÉDIA DE TODOS OS ROSTOS\n",
    "def land_med(points):\n",
    "    \n",
    "    index = 0\n",
    "\n",
    "    getPoints('../Landmarks/shape_predictor_81_face_landmarks.dat', '../Imagens/Ontario/train/teste2.jpg', '0')\n",
    "    img = cv2.imread('../Imagens/Ontario/woman/teste1.jpg')\n",
    "    img[0:1800, 0:1350] = (255, 255, 255)\n",
    "\n",
    "    \n",
    "    for cont in range(81):\n",
    "        img[points[index][cont][1]: (points[index][cont][1]+10) , points[index][cont][0]: (points[index][cont][0]+10)] = (0, 0, 0)\n",
    "\n",
    "#3º PASSO (MÁSCARA - LINHAS): APLICAMOS A MÉDIA DOS PONTOS EM UMA IMAGEM EM BRANCO, ASSIM CRIANDO UMA MÁSCARA DA MÉDIA DE TODOS OS ROSTOS        \n",
    "def land_mask():\n",
    "    cv2.imwrite('../Imagens/Ontario/result/test_woman1.jpg',img)\n",
    "    img = cv2.imread('../Imagens/Ontario/woman/test_woman1.jpg')\n",
    "    \n",
    "    p68 = [[0, 16, False],\n",
    "           [17, 21, False],\n",
    "           [22, 26, False],\n",
    "           [27, 30, False],\n",
    "           [30, 35, True],\n",
    "           [36, 41, True],\n",
    "           [42, 47, True],\n",
    "           [48, 59, True],\n",
    "           [60, 67, True]]\n",
    "\n",
    "    for k in range(0, len(p68)):\n",
    "        pontos = []\n",
    "        for i in range(p68[k][0], p68[k][1] + 1):\n",
    "            ponto = [points[k][0], points[k][1]]\n",
    "            pontos.append(ponto)\n",
    "        pontos = np.array(pontos, dtype = np.int32)\n",
    "        cv2.polylines(img, [pontos], p68[k][2], (255,0,0), 2)\n",
    "\n",
    "    cv2.imwrite('../Imagens/Ontario/result/test_woman1.jpg',img)\n",
    "\n",
    "             \n",
    "def main():\n",
    "    ldmk_points = []\n",
    "    points = []\n",
    "    a = []\n",
    "\n",
    "    for i in range(1, len(os.listdir('../Imagens/Ontario/train/'))+1):\n",
    "        ldmk_points.append(getPoints('../Landmarks/shape_predictor_81_face_landmarks.dat', '../Imagens/Ontario/train/teste' + str(i) + '.jpg', '0'))\n",
    "\n",
    "    points.append((calculo(ldmk_points)))\n",
    "    land_med(points)\n",
    "    land_mask()\n",
    "    \n",
    "    return point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
